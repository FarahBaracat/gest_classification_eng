{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow to fit SVM per day of recording on selected gestrues (identified from Day 16/day 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "notebook_dir = os.getcwd()\n",
    "project_dir = os.path.dirname(notebook_dir)\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.insert(0, project_dir)\n",
    "\n",
    "from srcs.engdataset import ENGDataset, Nerve\n",
    "import utils.preprocessing as pre\n",
    "import utils.classify as classify\n",
    "import utils.plot as uplot\n",
    "from constants import *\n",
    "\n",
    "from collections import Counter\n",
    "import logging\n",
    "from collections import namedtuple\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "plt.rcParams.update({\"figure.dpi\": 150})\n",
    "plt.rcParams['axes.axisbelow'] = True\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "matplotlib.rcParams.update({'font.size': 6})\n",
    "\n",
    "plt.rcParams.update({\n",
    "            \"figure.dpi\": 150, 'font.size': 10,\n",
    "            'figure.figsize': (5,3), 'axes.axisbelow': True,\n",
    "            'axes.edgecolor': COLOR_DICT['clouds'], 'axes.linewidth': 0.4\n",
    "        })\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load ENG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# load raw ENG for the following parameters\n",
    "day = 16                   # day of recording: can be 16, 17 or 23\n",
    "session = '01'             # session of recording\n",
    "\n",
    "preproc_plots = False      # whether to plot figures during preprocessing\n",
    "filter_signal = True      # whether to filter all channels or reload a saved file with filtered data\n",
    "save_figs = True\n",
    "optimize_mem = True        # whether to save some memory by deleting raw df once not needed.\n",
    "\n",
    "feature = 'power'\n",
    "wind_size = 0.100          # window size in seconds\n",
    "overlap_perc = 0.5          # overlap ratio\n",
    "organize_strat = 'flx_vs_ext_separate'     #  defines how to prepare the dataset: 'flx_vs_ext_separate' or 'flx_vs_ext_together' or'flx_vs_ext_combined'\n",
    "\n",
    "# Select only few classes from all for classification\n",
    "Gest_namedtup = namedtuple('gesture', ['id', 'phase'])\n",
    "sel_gest_phase = [Gest_namedtup(0, 'Open'),\n",
    "                  Gest_namedtup(1, 'Close'),\n",
    "                  # Gest_namedtup(2,'Close'),\n",
    "                  Gest_namedtup(3, 'Close'),\n",
    "                  Gest_namedtup(4, 'Close')]\n",
    "\n",
    "\n",
    "# Classifier parameters\n",
    "seed = 10     # random seed used for splitting the k-folds\n",
    "k_cv = 5     # number of k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory for figures\n",
    "directories = [FIG_DIR, CLF_FIG, FILTERED_DIR, CLF_RESULTS_DIR]\n",
    "\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "CLF_FIG = os.path.join(FIG_DIR, 'clf')\n",
    "if not os.path.exists(CLF_FIG):\n",
    "    os.makedirs(CLF_FIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_dataset = ENGDataset(day= day, session=session, load_raw_data = True, save_figs=save_figs)\n",
    "pipeline = {'bp_order': 3, 'bp_cutoff_freq': np.array([300, 2000]), 'notch_bandwidth': 0.5, 'notch_reject': 50}\n",
    "eng_dataset.filt_pipeline = pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_matfile_vars(data):\n",
    "    for key in data.keys():\n",
    "        if isinstance(data[key], np.ndarray):\n",
    "            print(f\"{key}: {data[key].dtype} {data[key].shape} \")\n",
    "        if isinstance(data[key], list):\n",
    "            print(f\"{key}: list {len(data[key])}\")\n",
    "    print(\"\\n\")\n",
    "show_matfile_vars(eng_dataset.raw_data)\n",
    "show_matfile_vars(eng_dataset.post_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Filter the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_signal: # filter all channels and plot the bandpassed version\n",
    "    notch_filt_data, bp_filt_data = pre.apply_filter_pipeline(eng_dataset)\n",
    "\n",
    "    if preproc_plots:\n",
    "    # plot single ch fft after filtering\n",
    "        fig = plt.figure(figsize=(8, 4))\n",
    "        gs = gridspec.GridSpec(nrows=3, ncols=1)\n",
    "        sel_ch = 0\n",
    "        xlim = [0,  pipeline['bp_cutoff_freq'][-1]]  # in Hz\n",
    "\n",
    "        xf_raw, yf_raw = pre.get_fft(np.array(eng_dataset.post_data_df[sel_ch]), ENG_FS)\n",
    "\n",
    "        xf_bp, yf_bp = pre.get_fft(bp_filt_data[:, sel_ch], ENG_FS)\n",
    "        xf_not, yf_not = pre.get_fft(notch_filt_data[:, sel_ch], ENG_FS)\n",
    "\n",
    "        ax = fig.add_subplot(gs[0])\n",
    "        ax.plot(xf_raw, np.sqrt(np.abs(yf_raw)), label='raw', color=COLOR_DICT['midnight_blue'])\n",
    "        ax.set(frame_on=False)\n",
    "        plt.xlim(xlim)\n",
    "        plt.ylabel('amplitude [uV]')\n",
    "        plt.title(f\"Signal ch:{sel_ch} after Notch filters + BP: {pipeline['bp_cutoff_freq']}\", fontsize=8)\n",
    "\n",
    "        ax2 = fig.add_subplot(gs[1])\n",
    "        ax2.plot(xf_not, np.sqrt(np.abs(yf_not)), label='Notch', color=COLOR_DICT['pumpkin'])\n",
    "        ax2.set(frame_on=False)\n",
    "        plt.legend()\n",
    "        plt.xlim(xlim)\n",
    "\n",
    "        # plt.xticks(ticks=np.arange(-0,1000,50))\n",
    "        plt.ylabel('amplitude [uV]')\n",
    "\n",
    "        ax1 = fig.add_subplot(gs[2])\n",
    "        ax1.plot(xf_bp, np.sqrt(np.abs(yf_bp)), label='BPF', color=COLOR_DICT['midnight_blue'])\n",
    "        ax1.set(frame_on=False)\n",
    "        plt.legend()\n",
    "        plt.xlim(xlim)\n",
    "        plt.ylabel('amplitude [uV]')\n",
    "        plt.xlabel('freq [Hz]')\n",
    "        plt.show()\n",
    "\n",
    "        fig.savefig(f\"figures/fft_bp_{pipeline['bp_cutoff_freq'][0]}_\"\n",
    "                    f\"{pipeline['bp_cutoff_freq'][1]}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save filtered data to pickle or load from pickle a presaved filtered data\n",
    "filt_filename = f\"day{eng_dataset.day}{eng_dataset.session}_eng_filt_{eng_dataset.filt_pipeline['bp_cutoff_freq'][0]}_{eng_dataset.filt_pipeline['bp_cutoff_freq'][1]}.pkl\"\n",
    "if filter_signal:\n",
    "    # organize filtered data in dataframe\n",
    "    filt_df = pd.DataFrame(bp_filt_data)\n",
    "    filt_df[TIME_VAR] = eng_dataset.post_data_df[TIME_VAR]\n",
    "    filt_df.to_pickle(os.path.join(FILTERED_DIR, filt_filename))\n",
    "else:\n",
    "    logging.info(f\"Loading filtered data from {filt_filename}\")\n",
    "    filt_df = pd.read_pickle(os.path.join(FILTERED_DIR, filt_filename))\n",
    "eng_dataset.filt_df = filt_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_channels, bad_channels_std = pre.detect_bad_channels(eng_dataset, std_threshold=6)\n",
    "print(f\"Bad channels:{bad_channels}\\nBad channels std:{np.round(bad_channels_std,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot bad channels\n",
    "# fig = plt.figure(figsize=(8, 4))\n",
    "# gs = gridspec.GridSpec(nrows=4, ncols=2)\n",
    "# bad_channels_good = bad_channels + [43,0]\n",
    "# for i, ch in enumerate(bad_channels_good):\n",
    "#     ax = fig.add_subplot(gs[i])\n",
    "#     ax.plot(eng_dataset.filt_df[TIME_VAR], eng_dataset.filt_df[ch], label='raw', color=COLOR_DICT['midnight_blue'])\n",
    "#     plt.ylabel('amplitude [uV]')\n",
    "#     plt.title(f\"Bad channel {ch}\")\n",
    "#     # ax.set_xlim([5.645, 5.8])\n",
    "#     # ax.set_ylim([-800,800])\n",
    "\n",
    "# fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unfold each rep in time and fit SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizing some memory\n",
    "if optimize_mem:\n",
    "    eng_dataset._detete_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_channels, wind_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df, labels_map = classify.prepare_input_df(eng_dataset, feature, organize_strat,  wind_size, overlap_perc)\n",
    "avg_win_per_class = input_df.groupby([LABEL_COL],as_index=True)[FEAT_WIN_COL].count() / input_df.groupby([LABEL_COL],as_index=True)[REP_ID_COL].nunique()\n",
    "print(f\"Average number of windows per class\\n{avg_win_per_class}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "select_class, select_class_labels = pre.encode_gest_phase(eng_dataset, sel_gest_phase, labels_map)\n",
    "print(f\"Selected classes:{select_class} with names:\\n{select_class_labels}\")\n",
    "results_df = classify.fit_svm(input_df, labels_map, select_class, eng_dataset,\n",
    "                              annotate_cm=False,\n",
    "                              seed=seed,\n",
    "                              is_temporal=True,\n",
    "                              k_cv=k_cv,\n",
    "                              bad_channels=[], # old code, [1,2,43] for day 16, session 01\n",
    "                              bin_width=wind_size,\n",
    "                              bin_stat=feature,\n",
    "                              exp_var=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fr\"Mean balanced acc across all classes:{np.round(results_df['acc_val'].mean(),4)*100} % +- {np.round(results_df['acc_val'].std(),4)*100} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
