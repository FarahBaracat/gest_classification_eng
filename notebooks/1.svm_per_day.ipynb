{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow to fit SVM per day of recording on selected gestrues (identified from Day 16/day 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "notebook_dir = os.getcwd()\n",
    "project_dir = os.path.dirname(notebook_dir)\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.insert(0, project_dir)\n",
    "\n",
    "from srcs.engdataset import ENGDataset, Nerve\n",
    "import utils.preprocessing as pre\n",
    "import utils.classify as classify\n",
    "import utils.plot as uplot\n",
    "from constants import *\n",
    "\n",
    "from collections import Counter\n",
    "import logging\n",
    "from collections import namedtuple\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "plt.rcParams.update({\"figure.dpi\": 150})\n",
    "plt.rcParams['axes.axisbelow'] = True\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "matplotlib.rcParams.update({'font.size': 6})\n",
    "\n",
    "plt.rcParams.update({\n",
    "            \"figure.dpi\": 150, 'font.size': 10,\n",
    "            'figure.figsize': (5,3), 'axes.axisbelow': True,\n",
    "            'axes.edgecolor': COLOR_DICT['clouds'], 'axes.linewidth': 0.4\n",
    "        })\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load ENG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# load raw ENG for the following parameters\n",
    "day = 16                   # day of recording: can be 16, 17 or 23\n",
    "session = '01'             # session of recording\n",
    "\n",
    "preproc_plots = False      # whether to plot figures during preprocessing\n",
    "filter_signal = False      # whether to filter all channels or reload a saved file with filtered data\n",
    "save_figs = True\n",
    "optimize_mem = True        # whether to save some memory by deleting raw df once not needed.\n",
    "\n",
    "feature = 'power'\n",
    "wind_size = 0.100          # window size in seconds\n",
    "overlap_perc = 0.5          # overlap ratio\n",
    "organize_strat = 'flx_vs_ext_separate'     #  defines how to prepare the dataset: 'flx_vs_ext_separate' or 'flx_vs_ext_together' or'flx_vs_ext_combined'\n",
    "\n",
    "# Select only few classes from all for classification\n",
    "Gest_namedtup = namedtuple('gesture', ['id', 'phase'])\n",
    "sel_gest_phase = [Gest_namedtup(0, 'Close'),\n",
    "                  Gest_namedtup(1, 'Close'),\n",
    "                  # Gest_namedtup(2,'Close'),\n",
    "                  Gest_namedtup(3, 'Close'),\n",
    "                  Gest_namedtup(4, 'Close')]\n",
    "\n",
    "\n",
    "# Classifier parameters\n",
    "seed = 10     # random seed used for splitting the k-folds\n",
    "k_cv = 5     # number of k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory for figures\n",
    "directories = [FIG_DIR, CLF_FIG, FILTERED_DIR, CLF_RESULTS_DIR]\n",
    "\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "CLF_FIG = os.path.join(FIG_DIR, 'clf')\n",
    "if not os.path.exists(CLF_FIG):\n",
    "    os.makedirs(CLF_FIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from /Users/farahbaracat/Library/CloudStorage/OneDrive-UniversitätZürichUZH/ENG upper dataset/Data_TIME_Marina/day16/AM_prese_1601_raw_ENG.mat\n",
      "INFO:root:Loading data from /Users/farahbaracat/Library/CloudStorage/OneDrive-UniversitätZürichUZH/ENG upper dataset/Data_TIME_Marina/day16/AM_prese_1601_raw_ENG_ok.mat\n",
      "INFO:root:Creating dictionary of reps count per task: {0: 10, 1: 10, 2: 10, 3: 7, 4: 10}\n",
      "INFO:root:Time column of post_data(7157879,) \n",
      "Rec column of post_data(56, 7157879)\n"
     ]
    }
   ],
   "source": [
    "eng_dataset = ENGDataset(day= day, session=session, load_raw_data = True, save_figs=save_figs)\n",
    "pipeline = {'bp_order': 3, 'bp_cutoff_freq': np.array([300, 2000]), 'notch_bandwidth': 0.5, 'notch_reject': 50}\n",
    "eng_dataset.filt_pipeline = pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REC: float64 (56, 7607880) \n",
      "Time: float64 (7607880,) \n",
      "Trigger: float64 (49,) \n",
      "\n",
      "\n",
      "REC: float64 (56, 7157879) \n",
      "SEGM_tot: list 5\n",
      "Trigger: float64 (47,) \n",
      "Time: float64 (7157879,) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_matfile_vars(data):\n",
    "    for key in data.keys():\n",
    "        if isinstance(data[key], np.ndarray):\n",
    "            print(f\"{key}: {data[key].dtype} {data[key].shape} \")\n",
    "        if isinstance(data[key], list):\n",
    "            print(f\"{key}: list {len(data[key])}\")\n",
    "    print(\"\\n\")\n",
    "show_matfile_vars(eng_dataset.raw_data)\n",
    "show_matfile_vars(eng_dataset.post_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Filter the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_signal: # filter all channels and plot the bandpassed version\n",
    "    notch_filt_data, bp_filt_data = pre.apply_filter_pipeline(eng_dataset)\n",
    "\n",
    "    if preproc_plots:\n",
    "    # plot single ch fft after filtering\n",
    "        fig = plt.figure(figsize=(8, 4))\n",
    "        gs = gridspec.GridSpec(nrows=3, ncols=1)\n",
    "        sel_ch = 0\n",
    "        xlim = [0,  pipeline['bp_cutoff_freq'][-1]]  # in Hz\n",
    "\n",
    "        xf_raw, yf_raw = pre.get_fft(np.array(eng_dataset.post_data_df[sel_ch]), ENG_FS)\n",
    "\n",
    "        xf_bp, yf_bp = pre.get_fft(bp_filt_data[:, sel_ch], ENG_FS)\n",
    "        xf_not, yf_not = pre.get_fft(notch_filt_data[:, sel_ch], ENG_FS)\n",
    "\n",
    "        ax = fig.add_subplot(gs[0])\n",
    "        ax.plot(xf_raw, np.sqrt(np.abs(yf_raw)), label='raw', color=COLOR_DICT['midnight_blue'])\n",
    "        ax.set(frame_on=False)\n",
    "        plt.xlim(xlim)\n",
    "        plt.ylabel('amplitude [uV]')\n",
    "        plt.title(f\"Signal ch:{sel_ch} after Notch filters + BP: {pipeline['bp_cutoff_freq']}\", fontsize=8)\n",
    "\n",
    "        ax2 = fig.add_subplot(gs[1])\n",
    "        ax2.plot(xf_not, np.sqrt(np.abs(yf_not)), label='Notch', color=COLOR_DICT['pumpkin'])\n",
    "        ax2.set(frame_on=False)\n",
    "        plt.legend()\n",
    "        plt.xlim(xlim)\n",
    "\n",
    "        # plt.xticks(ticks=np.arange(-0,1000,50))\n",
    "        plt.ylabel('amplitude [uV]')\n",
    "\n",
    "        ax1 = fig.add_subplot(gs[2])\n",
    "        ax1.plot(xf_bp, np.sqrt(np.abs(yf_bp)), label='BPF', color=COLOR_DICT['midnight_blue'])\n",
    "        ax1.set(frame_on=False)\n",
    "        plt.legend()\n",
    "        plt.xlim(xlim)\n",
    "        plt.ylabel('amplitude [uV]')\n",
    "        plt.xlabel('freq [Hz]')\n",
    "        plt.show()\n",
    "\n",
    "        fig.savefig(f\"figures/fft_bp_{pipeline['bp_cutoff_freq'][0]}_\"\n",
    "                    f\"{pipeline['bp_cutoff_freq'][1]}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading filtered data from day1601_eng_filt_300_2000.pkl\n"
     ]
    }
   ],
   "source": [
    "# save filtered data to pickle or load from pickle a presaved filtered data\n",
    "filt_filename = f\"day{eng_dataset.day}{eng_dataset.session}_eng_filt_{eng_dataset.filt_pipeline['bp_cutoff_freq'][0]}_{eng_dataset.filt_pipeline['bp_cutoff_freq'][1]}.pkl\"\n",
    "if filter_signal:\n",
    "    # organize filtered data in dataframe\n",
    "    filt_df = pd.DataFrame(bp_filt_data)\n",
    "    filt_df[TIME_VAR] = eng_dataset.post_data_df[TIME_VAR]\n",
    "    filt_df.to_pickle(os.path.join(FILTERED_DIR, filt_filename))\n",
    "else:\n",
    "    logging.info(f\"Loading filtered data from {filt_filename}\")\n",
    "    filt_df = pd.read_pickle(os.path.join(FILTERED_DIR, filt_filename))\n",
    "eng_dataset.filt_df = filt_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Nerve.MEDIAN_E1: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "Channels median of stds: 0.9994738317477818\n",
      "\n",
      "INFO:root:Nerve.MEDIAN_E2: [14 15 16 17 18 19 20 21 22 23 24 25 26 27]\n",
      "Channels median of stds: 1.5129269970719061\n",
      "\n",
      "INFO:root:Nerve.ULNAR_E1: [28 29 30 31 32 33 34 35 36 37 38 39 40 41]\n",
      "Channels median of stds: 1.2218176684677338\n",
      "\n",
      "INFO:root:Nerve.ULNAR_E2: [42 43 44 45 46 47 48 49 50 51 52 53 54 55]\n",
      "Channels median of stds: 1.3015219241400366\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad channels:[1, 2, 5, 7]\n",
      "Bad channels std:[8.39  6.585 6.036 6.101]\n"
     ]
    }
   ],
   "source": [
    "bad_channels, bad_channels_std = pre.detect_bad_channels(eng_dataset, std_threshold=6)\n",
    "print(f\"Bad channels:{bad_channels}\\nBad channels std:{np.round(bad_channels_std,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot bad channels\n",
    "# fig = plt.figure(figsize=(8, 4))\n",
    "# gs = gridspec.GridSpec(nrows=4, ncols=2)\n",
    "# bad_channels_good = bad_channels + [43,0]\n",
    "# for i, ch in enumerate(bad_channels_good):\n",
    "#     ax = fig.add_subplot(gs[i])\n",
    "#     ax.plot(eng_dataset.filt_df[TIME_VAR], eng_dataset.filt_df[ch], label='raw', color=COLOR_DICT['midnight_blue'])\n",
    "#     plt.ylabel('amplitude [uV]')\n",
    "#     plt.title(f\"Bad channel {ch}\")\n",
    "#     # ax.set_xlim([5.645, 5.8])\n",
    "#     # ax.set_ylim([-800,800])\n",
    "\n",
    "# fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unfold each rep in time and fit SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizing some memory\n",
    "if optimize_mem:\n",
    "    eng_dataset._detete_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 5, 7], 0.1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_channels, wind_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:clf_df['label'].unique():[0 2 6 8]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of windows per class\n",
      "class_label\n",
      "0     19.0\n",
      "1     19.0\n",
      "2     19.0\n",
      "3     19.0\n",
      "4     19.0\n",
      "5     19.0\n",
      "6     19.0\n",
      "7     19.0\n",
      "8     19.0\n",
      "9     19.0\n",
      "10    89.3\n",
      "dtype: float64\n",
      "\n",
      "Gesture id:0  task:Tripod  phase:Close\n",
      "Gesture id:1  task:ThOpp.  phase:Close\n",
      "Gesture id:3  task:UlnarFing.  phase:Close\n",
      "Gesture id:4  task:FingAbd.  phase:Close\n",
      "Selected classes:[0, 2, 6, 8] with names:\n",
      "['Tripod Close', 'ThOpp. Close', 'UlnarFing. Close', 'FingAbd.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fold 0\n",
      "-------------\n",
      "Train sample ids:[ 0  1  2  3  4  7  8  9 10 11 12 13 14 15 16 17 21 22 23 25 26 28 29 30\n",
      " 31 32 33 34 35]\n",
      "Test sample ids:[ 5  6 18 19 20 24 27 36]\n",
      "Counter train:Counter({0: 152, 2: 152, 8: 152, 6: 95})\n",
      "Counter test: Counter({0: 38, 2: 38, 6: 38, 8: 38}) \n",
      "pred_labels: [0 2 6 8]\n",
      "INFO:root:Train: (551, 56) , (551,) Test: (152, 56) , (152,)\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df, labels_map = classify.prepare_input_df(eng_dataset, feature, organize_strat,  wind_size, overlap_perc)\n",
    "avg_win_per_class = input_df.groupby([LABEL_COL],as_index=True)[FEAT_WIN_COL].count() / input_df.groupby([LABEL_COL],as_index=True)[REP_ID_COL].nunique()\n",
    "print(f\"Average number of windows per class\\n{avg_win_per_class}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "select_class, select_class_labels = pre.encode_gest_phase(eng_dataset, sel_gest_phase, labels_map)\n",
    "print(f\"Selected classes:{select_class} with names:\\n{select_class_labels}\")\n",
    "results_df = classify.fit_svm(input_df, labels_map, select_class, eng_dataset,\n",
    "                              annotate_cm=False,\n",
    "                              seed=seed,\n",
    "                              is_temporal=True,\n",
    "                              k_cv=k_cv,\n",
    "                              bad_channels=[], # old code, [1,2,43] for day 16, session 01\n",
    "                              bin_width=wind_size,\n",
    "                              bin_stat=feature,\n",
    "                              exp_var=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_val</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_val</th>\n",
       "      <th>prec_train</th>\n",
       "      <th>prec_val</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.867105</td>\n",
       "      <td>0.638158</td>\n",
       "      <td>0.881544</td>\n",
       "      <td>0.626902</td>\n",
       "      <td>0.886312</td>\n",
       "      <td>0.692042</td>\n",
       "      <td>0.883848</td>\n",
       "      <td>0.638158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884868</td>\n",
       "      <td>0.743421</td>\n",
       "      <td>0.894261</td>\n",
       "      <td>0.739145</td>\n",
       "      <td>0.894550</td>\n",
       "      <td>0.771667</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.743421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.908991</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.912110</td>\n",
       "      <td>0.656232</td>\n",
       "      <td>0.913722</td>\n",
       "      <td>0.658984</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.669173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.939145</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.942009</td>\n",
       "      <td>0.577968</td>\n",
       "      <td>0.942102</td>\n",
       "      <td>0.645589</td>\n",
       "      <td>0.942105</td>\n",
       "      <td>0.586466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.884320</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.885772</td>\n",
       "      <td>0.640396</td>\n",
       "      <td>0.887822</td>\n",
       "      <td>0.669106</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.639098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_train   acc_val  f1_train    f1_val  prec_train  prec_val  \\\n",
       "0   0.867105  0.638158  0.881544  0.626902    0.886312  0.692042   \n",
       "1   0.884868  0.743421  0.894261  0.739145    0.894550  0.771667   \n",
       "2   0.908991  0.618421  0.912110  0.656232    0.913722  0.658984   \n",
       "3   0.939145  0.565789  0.942009  0.577968    0.942102  0.645589   \n",
       "4   0.884320  0.585526  0.885772  0.640396    0.887822  0.669106   \n",
       "\n",
       "   recall_train  recall_val  \n",
       "0      0.883848    0.638158  \n",
       "1      0.894737    0.743421  \n",
       "2      0.912281    0.669173  \n",
       "3      0.942105    0.586466  \n",
       "4      0.885965    0.639098  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc_train       0.896886\n",
       "acc_val         0.630263\n",
       "f1_train        0.903139\n",
       "f1_val          0.648129\n",
       "prec_train      0.904901\n",
       "prec_val        0.687477\n",
       "recall_train    0.903787\n",
       "recall_val      0.655263\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean balanced acc across all classes:63.029999999999994 % +- 6.92 %\n"
     ]
    }
   ],
   "source": [
    "print(fr\"Mean balanced acc across all classes:{np.round(results_df['acc_val'].mean(),4)*100} % +- {np.round(results_df['acc_val'].std(),4)*100} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
